{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ZNhGcW6q6r"
      },
      "source": [
        "# Student Loan Risk with Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0otrXpJc6q6u"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpV4Y-3Z6q6w"
      },
      "source": [
        "---\n",
        "\n",
        "## Prepare the data to be used on a neural network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUuSzp2l6q6w"
      },
      "source": [
        "### Step 1: Read the `student-loans.csv` file into a Pandas DataFrame. Review the DataFrame, looking for columns that could eventually define your features and target variables.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "G65km1KD6q6x",
        "outputId": "93d12d8d-c415-4017-8452-5b4966e4dde5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>payment_history</th>\n",
              "      <th>location_parameter</th>\n",
              "      <th>stem_degree_score</th>\n",
              "      <th>gpa_ranking</th>\n",
              "      <th>alumni_success</th>\n",
              "      <th>study_major_code</th>\n",
              "      <th>time_to_completion</th>\n",
              "      <th>finance_workshop_score</th>\n",
              "      <th>cohort_ranking</th>\n",
              "      <th>total_loan_score</th>\n",
              "      <th>financial_aid_score</th>\n",
              "      <th>credit_ranking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      payment_history  location_parameter  stem_degree_score  gpa_ranking  \\\n",
              "0                 7.4               0.700               0.00          1.9   \n",
              "1                 7.8               0.880               0.00          2.6   \n",
              "2                 7.8               0.760               0.04          2.3   \n",
              "3                11.2               0.280               0.56          1.9   \n",
              "4                 7.4               0.700               0.00          1.9   \n",
              "...               ...                 ...                ...          ...   \n",
              "1594              6.2               0.600               0.08          2.0   \n",
              "1595              5.9               0.550               0.10          2.2   \n",
              "1596              6.3               0.510               0.13          2.3   \n",
              "1597              5.9               0.645               0.12          2.0   \n",
              "1598              6.0               0.310               0.47          3.6   \n",
              "\n",
              "      alumni_success  study_major_code  time_to_completion  \\\n",
              "0              0.076              11.0                34.0   \n",
              "1              0.098              25.0                67.0   \n",
              "2              0.092              15.0                54.0   \n",
              "3              0.075              17.0                60.0   \n",
              "4              0.076              11.0                34.0   \n",
              "...              ...               ...                 ...   \n",
              "1594           0.090              32.0                44.0   \n",
              "1595           0.062              39.0                51.0   \n",
              "1596           0.076              29.0                40.0   \n",
              "1597           0.075              32.0                44.0   \n",
              "1598           0.067              18.0                42.0   \n",
              "\n",
              "      finance_workshop_score  cohort_ranking  total_loan_score  \\\n",
              "0                    0.99780            3.51              0.56   \n",
              "1                    0.99680            3.20              0.68   \n",
              "2                    0.99700            3.26              0.65   \n",
              "3                    0.99800            3.16              0.58   \n",
              "4                    0.99780            3.51              0.56   \n",
              "...                      ...             ...               ...   \n",
              "1594                 0.99490            3.45              0.58   \n",
              "1595                 0.99512            3.52              0.76   \n",
              "1596                 0.99574            3.42              0.75   \n",
              "1597                 0.99547            3.57              0.71   \n",
              "1598                 0.99549            3.39              0.66   \n",
              "\n",
              "      financial_aid_score  credit_ranking  \n",
              "0                     9.4               0  \n",
              "1                     9.8               0  \n",
              "2                     9.8               0  \n",
              "3                     9.8               1  \n",
              "4                     9.4               0  \n",
              "...                   ...             ...  \n",
              "1594                 10.5               0  \n",
              "1595                 11.2               1  \n",
              "1596                 11.0               1  \n",
              "1597                 10.2               0  \n",
              "1598                 11.0               1  \n",
              "\n",
              "[1599 rows x 12 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the csv into a Pandas DataFrame\n",
        "file_path = \"https://static.bc-edx.com/ai/ail-v-1-0/m18/lms/datasets/student-loans.csv\"\n",
        "loans_df = pd.read_csv(file_path)\n",
        "\n",
        "# Review the DataFrame\n",
        "loans_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8ZYB8wx6q6x",
        "outputId": "b509fc34-4488-406e-e451-2069fec37371"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "payment_history           float64\n",
              "location_parameter        float64\n",
              "stem_degree_score         float64\n",
              "gpa_ranking               float64\n",
              "alumni_success            float64\n",
              "study_major_code          float64\n",
              "time_to_completion        float64\n",
              "finance_workshop_score    float64\n",
              "cohort_ranking            float64\n",
              "total_loan_score          float64\n",
              "financial_aid_score       float64\n",
              "credit_ranking              int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Review the data types associated with the columns\n",
        "loans_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P8aX-dW75JO",
        "outputId": "63251fa8-5ac1-4112-c2f7-bc5d97ea8491"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "credit_ranking\n",
              "1    855\n",
              "0    744\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the credit_ranking value counts\n",
        "loans_df[\"credit_ranking\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6vbZeDH6q6y"
      },
      "source": [
        "### Step 2: Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “credit_ranking”. The remaining columns should define the features dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5eVAP5M6q6y",
        "outputId": "89728bbf-6930-4573-a126-9f1b66ed8859"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [1],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the target set y using the credit_ranking column\n",
        "y = loans_df['credit_ranking'].values.reshape(-1, 1)\n",
        "\n",
        "# Display a sample of y\n",
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "IIkrD2Sn6q6z",
        "outputId": "ce07c4a3-fb81-4657-d11e-ec85ae8554c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>payment_history</th>\n",
              "      <th>location_parameter</th>\n",
              "      <th>stem_degree_score</th>\n",
              "      <th>gpa_ranking</th>\n",
              "      <th>alumni_success</th>\n",
              "      <th>study_major_code</th>\n",
              "      <th>time_to_completion</th>\n",
              "      <th>finance_workshop_score</th>\n",
              "      <th>cohort_ranking</th>\n",
              "      <th>total_loan_score</th>\n",
              "      <th>financial_aid_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      payment_history  location_parameter  stem_degree_score  gpa_ranking  \\\n",
              "0                 7.4               0.700               0.00          1.9   \n",
              "1                 7.8               0.880               0.00          2.6   \n",
              "2                 7.8               0.760               0.04          2.3   \n",
              "3                11.2               0.280               0.56          1.9   \n",
              "4                 7.4               0.700               0.00          1.9   \n",
              "...               ...                 ...                ...          ...   \n",
              "1594              6.2               0.600               0.08          2.0   \n",
              "1595              5.9               0.550               0.10          2.2   \n",
              "1596              6.3               0.510               0.13          2.3   \n",
              "1597              5.9               0.645               0.12          2.0   \n",
              "1598              6.0               0.310               0.47          3.6   \n",
              "\n",
              "      alumni_success  study_major_code  time_to_completion  \\\n",
              "0              0.076              11.0                34.0   \n",
              "1              0.098              25.0                67.0   \n",
              "2              0.092              15.0                54.0   \n",
              "3              0.075              17.0                60.0   \n",
              "4              0.076              11.0                34.0   \n",
              "...              ...               ...                 ...   \n",
              "1594           0.090              32.0                44.0   \n",
              "1595           0.062              39.0                51.0   \n",
              "1596           0.076              29.0                40.0   \n",
              "1597           0.075              32.0                44.0   \n",
              "1598           0.067              18.0                42.0   \n",
              "\n",
              "      finance_workshop_score  cohort_ranking  total_loan_score  \\\n",
              "0                    0.99780            3.51              0.56   \n",
              "1                    0.99680            3.20              0.68   \n",
              "2                    0.99700            3.26              0.65   \n",
              "3                    0.99800            3.16              0.58   \n",
              "4                    0.99780            3.51              0.56   \n",
              "...                      ...             ...               ...   \n",
              "1594                 0.99490            3.45              0.58   \n",
              "1595                 0.99512            3.52              0.76   \n",
              "1596                 0.99574            3.42              0.75   \n",
              "1597                 0.99547            3.57              0.71   \n",
              "1598                 0.99549            3.39              0.66   \n",
              "\n",
              "      financial_aid_score  \n",
              "0                     9.4  \n",
              "1                     9.8  \n",
              "2                     9.8  \n",
              "3                     9.8  \n",
              "4                     9.4  \n",
              "...                   ...  \n",
              "1594                 10.5  \n",
              "1595                 11.2  \n",
              "1596                 11.0  \n",
              "1597                 10.2  \n",
              "1598                 11.0  \n",
              "\n",
              "[1599 rows x 11 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define features set X by selecting all columns but credit_ranking\n",
        "X = loans_df.drop(columns=['credit_ranking'])\n",
        "\n",
        "# Review the features DataFrame\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmM9c-tj6q6z"
      },
      "source": [
        "### Step 3: Split the features and target sets into training and testing datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OD7xwU_96q6z"
      },
      "outputs": [],
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "# Assign the function a random_state equal to 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9i6DHY06q6z"
      },
      "source": [
        "### Step 4: Use scikit-learn's `StandardScaler` to scale the features data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BzD3z20m6q6z"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the features training dataset\n",
        "X_train_fit = scaler.fit(X_train)\n",
        "X_train_scaled =scaler.transform(X_train)\n",
        "\n",
        "# Fit the scaler to the features training dataset\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZzVDjba6q6z"
      },
      "source": [
        "---\n",
        "\n",
        "## Compile and Evaluate a Model Using a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-pSux4Q6q60"
      },
      "source": [
        "### Step 1: Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
        "\n",
        "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5C94FCd6q60",
        "outputId": "cbf05783-2f56-4745-cd33-649a6152e510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n"
          ]
        }
      ],
      "source": [
        "# Define the the number of inputs (features) to the model\n",
        "input_nodes = len(X.columns)\n",
        "\n",
        "# Review the number of features\n",
        "print(input_nodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c_KXDLkF6q60"
      },
      "outputs": [],
      "source": [
        "# Define the number of hidden nodes for the first hidden layer\n",
        "hiddenUnits1 = 11\n",
        "\n",
        "\n",
        "# Define the number of hidden nodes for the second hidden layer\n",
        "hiddenUnits2 = 7\n",
        "\n",
        "\n",
        "# Define the number of neurons in the output layer\n",
        "outputUnits = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "63UdFncw6q60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jenniferleone/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Create the Sequential model instance\n",
        "from keras.models import Sequential\n",
        "nn_model = Sequential()\n",
        "\n",
        "# Add the first hidden layer\n",
        "nn_model.add(tf.keras.layers.Dense(units=hiddenUnits1, activation=\"relu\", input_dim=input_nodes))\n",
        "\n",
        "# Add the second hidden layer\n",
        "nn_model.add(tf.keras.layers.Dense(units=hiddenUnits2, activation=\"relu\"))\n",
        "\n",
        "# Add the output layer to the model specifying the number of output neurons and activation function\n",
        "nn_model.add(tf.keras.layers.Dense(units=outputUnits, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Beoh4f_6q61",
        "outputId": "2e50f810-086b-4d89-bf7d-98afbe0d649d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m132\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m84\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the Sequential model summary\n",
        "nn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRqWGIRo6q61"
      },
      "source": [
        "### Step 2: Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E-hZaeSn6q61"
      },
      "outputs": [],
      "source": [
        "# Compile the Sequential model\n",
        "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x25e8Idc6q61",
        "outputId": "e95946ba-23da-47a3-a1c1-5e9a2a484a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.4945 - loss: 0.7159 \n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.5530 - loss: 0.6713\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.6685 - loss: 0.6348\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.6929 - loss: 0.6052\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7133 - loss: 0.5759\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7012 - loss: 0.5785\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7368 - loss: 0.5403\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7317 - loss: 0.5429\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7565 - loss: 0.5128\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7192 - loss: 0.5387\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.7391 - loss: 0.5185\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7371 - loss: 0.5231\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7350 - loss: 0.5316\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7542 - loss: 0.4914\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7521 - loss: 0.5073\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7527 - loss: 0.4999\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7535 - loss: 0.5000\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7512 - loss: 0.4915\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7292 - loss: 0.5108\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7486 - loss: 0.5067\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7737 - loss: 0.4838\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7630 - loss: 0.4838\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7336 - loss: 0.4986\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7539 - loss: 0.4920\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.7581 - loss: 0.4844\n",
            "Epoch 26/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7755 - loss: 0.4766\n",
            "Epoch 27/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7640 - loss: 0.4704\n",
            "Epoch 28/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7588 - loss: 0.4829\n",
            "Epoch 29/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7480 - loss: 0.5060\n",
            "Epoch 30/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7724 - loss: 0.4738\n",
            "Epoch 31/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7587 - loss: 0.4821\n",
            "Epoch 32/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7746 - loss: 0.4665\n",
            "Epoch 33/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7756 - loss: 0.4736\n",
            "Epoch 34/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7726 - loss: 0.4688\n",
            "Epoch 35/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7926 - loss: 0.4421\n",
            "Epoch 36/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7881 - loss: 0.4601\n",
            "Epoch 37/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.7774 - loss: 0.4629\n",
            "Epoch 38/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7683 - loss: 0.4627\n",
            "Epoch 39/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7768 - loss: 0.4621\n",
            "Epoch 40/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.7867 - loss: 0.4504\n",
            "Epoch 41/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7726 - loss: 0.4631\n",
            "Epoch 42/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7751 - loss: 0.4720\n",
            "Epoch 43/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7684 - loss: 0.4676\n",
            "Epoch 44/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.7832 - loss: 0.4617\n",
            "Epoch 45/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7709 - loss: 0.4643\n",
            "Epoch 46/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7837 - loss: 0.4586\n",
            "Epoch 47/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7790 - loss: 0.4609\n",
            "Epoch 48/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7742 - loss: 0.4549\n",
            "Epoch 49/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.7949 - loss: 0.4557\n",
            "Epoch 50/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7828 - loss: 0.4612\n"
          ]
        }
      ],
      "source": [
        "# Fit the model using 50 epochs and the training data\n",
        "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfHMPZVI6q61"
      },
      "source": [
        "### Step 3: Evaluate the model using the test data to determine the model’s loss and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hfVADKo6q61",
        "outputId": "7df473ad-3301-4b49-e5c3-16e1687cc1cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 - 0s - 4ms/step - accuracy: 0.7500 - loss: 0.5089\n",
            "Loss: 0.5088891386985779, Accuracy: 0.75\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
        "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "\n",
        "\n",
        "# Display the model loss and accuracy results\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpAv0rXA6q61"
      },
      "source": [
        "### Step 4: Save and export your model to a keras file, and name the file `student_loans.keras`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "q0MetN0W6q61"
      },
      "outputs": [],
      "source": [
        "# Set the model's file path\n",
        "file_path = Path(\"student_loans.keras\")\n",
        "\n",
        "\n",
        "# Export your model to a keras file\n",
        "nn_model.save(file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1opCDdN6q61"
      },
      "source": [
        "---\n",
        "## Predict Loan Repayment Success by Using your Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfIfpeiy6q61"
      },
      "source": [
        "### Step 1: Reload your saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OCET2mvW6q61"
      },
      "outputs": [],
      "source": [
        "# Set the model's file path\n",
        "file_path = Path(\"student_loans.keras\")\n",
        "\n",
        "# Load the model to a new object\n",
        "nn_imported = tf.keras.models.load_model(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPKooGw6q61"
      },
      "source": [
        "### Step 2: Make predictions on the testing data and save the predictions to a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vet7qjgx6q62",
        "outputId": "0925af42-7e12-4978-8396-2a2c1580e1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 - 0s - 3ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.24770223],\n",
              "       [0.48509648],\n",
              "       [0.8653271 ],\n",
              "       [0.761101  ],\n",
              "       [0.9807028 ],\n",
              "       [0.8839626 ],\n",
              "       [0.8989096 ],\n",
              "       [0.09645467],\n",
              "       [0.5598816 ],\n",
              "       [0.45655903],\n",
              "       [0.8569122 ],\n",
              "       [0.14884406],\n",
              "       [0.4537639 ],\n",
              "       [0.95003694],\n",
              "       [0.6174519 ],\n",
              "       [0.28982234],\n",
              "       [0.8937514 ],\n",
              "       [0.29857567],\n",
              "       [0.53793734],\n",
              "       [0.45649835],\n",
              "       [0.5493125 ],\n",
              "       [0.8024743 ],\n",
              "       [0.2484195 ],\n",
              "       [0.91420346],\n",
              "       [0.42095685],\n",
              "       [0.9382611 ],\n",
              "       [0.78478426],\n",
              "       [0.6446034 ],\n",
              "       [0.21715815],\n",
              "       [0.17663242],\n",
              "       [0.71358174],\n",
              "       [0.96668583],\n",
              "       [0.27137282],\n",
              "       [0.96027905],\n",
              "       [0.11564223],\n",
              "       [0.55753726],\n",
              "       [0.12729055],\n",
              "       [0.39007312],\n",
              "       [0.9753958 ],\n",
              "       [0.08413177],\n",
              "       [0.9491753 ],\n",
              "       [0.05312807],\n",
              "       [0.03451704],\n",
              "       [0.9332104 ],\n",
              "       [0.11363962],\n",
              "       [0.7012057 ],\n",
              "       [0.1376538 ],\n",
              "       [0.48160562],\n",
              "       [0.29096934],\n",
              "       [0.8173732 ],\n",
              "       [0.02765968],\n",
              "       [0.08391557],\n",
              "       [0.9275479 ],\n",
              "       [0.0588684 ],\n",
              "       [0.23370284],\n",
              "       [0.6157002 ],\n",
              "       [0.8377432 ],\n",
              "       [0.7315514 ],\n",
              "       [0.64632535],\n",
              "       [0.17080082],\n",
              "       [0.85273904],\n",
              "       [0.13759266],\n",
              "       [0.31737295],\n",
              "       [0.41885895],\n",
              "       [0.04799922],\n",
              "       [0.28308442],\n",
              "       [0.96896917],\n",
              "       [0.4853302 ],\n",
              "       [0.6651993 ],\n",
              "       [0.9724353 ],\n",
              "       [0.11564223],\n",
              "       [0.9557432 ],\n",
              "       [0.574618  ],\n",
              "       [0.72243196],\n",
              "       [0.1686255 ],\n",
              "       [0.421792  ],\n",
              "       [0.9495973 ],\n",
              "       [0.14265153],\n",
              "       [0.09572262],\n",
              "       [0.82107806],\n",
              "       [0.7681335 ],\n",
              "       [0.11106878],\n",
              "       [0.11406379],\n",
              "       [0.4182916 ],\n",
              "       [0.75071263],\n",
              "       [0.09455708],\n",
              "       [0.09281091],\n",
              "       [0.88439476],\n",
              "       [0.23672459],\n",
              "       [0.78778917],\n",
              "       [0.10094642],\n",
              "       [0.95583177],\n",
              "       [0.27206382],\n",
              "       [0.9362249 ],\n",
              "       [0.75984526],\n",
              "       [0.2901964 ],\n",
              "       [0.94671494],\n",
              "       [0.76511705],\n",
              "       [0.71581686],\n",
              "       [0.88346624],\n",
              "       [0.65995914],\n",
              "       [0.16751277],\n",
              "       [0.19256723],\n",
              "       [0.17425197],\n",
              "       [0.1076463 ],\n",
              "       [0.48210594],\n",
              "       [0.7374628 ],\n",
              "       [0.56436163],\n",
              "       [0.8293775 ],\n",
              "       [0.05322874],\n",
              "       [0.97060615],\n",
              "       [0.6515673 ],\n",
              "       [0.849024  ],\n",
              "       [0.35697645],\n",
              "       [0.47308767],\n",
              "       [0.98392135],\n",
              "       [0.24424195],\n",
              "       [0.11066855],\n",
              "       [0.1940418 ],\n",
              "       [0.11536276],\n",
              "       [0.06764212],\n",
              "       [0.98533833],\n",
              "       [0.90747476],\n",
              "       [0.0994678 ],\n",
              "       [0.29764244],\n",
              "       [0.4864304 ],\n",
              "       [0.8621724 ],\n",
              "       [0.31695637],\n",
              "       [0.7159662 ],\n",
              "       [0.7702239 ],\n",
              "       [0.31495687],\n",
              "       [0.24248582],\n",
              "       [0.9427433 ],\n",
              "       [0.1451603 ],\n",
              "       [0.79781586],\n",
              "       [0.70192194],\n",
              "       [0.09987924],\n",
              "       [0.9783794 ],\n",
              "       [0.40977988],\n",
              "       [0.33909777],\n",
              "       [0.26229396],\n",
              "       [0.57188374],\n",
              "       [0.57678694],\n",
              "       [0.09544109],\n",
              "       [0.7469435 ],\n",
              "       [0.9355069 ],\n",
              "       [0.4542098 ],\n",
              "       [0.05600541],\n",
              "       [0.7528695 ],\n",
              "       [0.85925317],\n",
              "       [0.5465763 ],\n",
              "       [0.97797626],\n",
              "       [0.30810913],\n",
              "       [0.25829652],\n",
              "       [0.8607376 ],\n",
              "       [0.9306046 ],\n",
              "       [0.940669  ],\n",
              "       [0.95469654],\n",
              "       [0.8393564 ],\n",
              "       [0.5617661 ],\n",
              "       [0.9010643 ],\n",
              "       [0.62674356],\n",
              "       [0.23625979],\n",
              "       [0.17065285],\n",
              "       [0.96868086],\n",
              "       [0.8752718 ],\n",
              "       [0.3363154 ],\n",
              "       [0.09658109],\n",
              "       [0.08465564],\n",
              "       [0.78665805],\n",
              "       [0.33618817],\n",
              "       [0.79425246],\n",
              "       [0.2629916 ],\n",
              "       [0.66211677],\n",
              "       [0.91349626],\n",
              "       [0.45353198],\n",
              "       [0.22932206],\n",
              "       [0.18158686],\n",
              "       [0.3029852 ],\n",
              "       [0.2901964 ],\n",
              "       [0.6779659 ],\n",
              "       [0.837856  ],\n",
              "       [0.7418803 ],\n",
              "       [0.06594453],\n",
              "       [0.95578814],\n",
              "       [0.985865  ],\n",
              "       [0.9524769 ],\n",
              "       [0.47549638],\n",
              "       [0.19061787],\n",
              "       [0.07858951],\n",
              "       [0.42175213],\n",
              "       [0.5215692 ],\n",
              "       [0.37916726],\n",
              "       [0.21926439],\n",
              "       [0.59098506],\n",
              "       [0.46091565],\n",
              "       [0.49539238],\n",
              "       [0.17958917],\n",
              "       [0.19221808],\n",
              "       [0.42236564],\n",
              "       [0.95735115],\n",
              "       [0.37921768],\n",
              "       [0.92311585],\n",
              "       [0.11729657],\n",
              "       [0.98481315],\n",
              "       [0.8221681 ],\n",
              "       [0.20534159],\n",
              "       [0.09883999],\n",
              "       [0.957291  ],\n",
              "       [0.7431316 ],\n",
              "       [0.18426558],\n",
              "       [0.7261533 ],\n",
              "       [0.19256723],\n",
              "       [0.9119373 ],\n",
              "       [0.15323502],\n",
              "       [0.2641008 ],\n",
              "       [0.09947258],\n",
              "       [0.2042394 ],\n",
              "       [0.8166958 ],\n",
              "       [0.5945175 ],\n",
              "       [0.6051959 ],\n",
              "       [0.16197248],\n",
              "       [0.20088832],\n",
              "       [0.39668372],\n",
              "       [0.8168581 ],\n",
              "       [0.66752815],\n",
              "       [0.35752365],\n",
              "       [0.6340426 ],\n",
              "       [0.98452073],\n",
              "       [0.5072756 ],\n",
              "       [0.20799072],\n",
              "       [0.23714966],\n",
              "       [0.94965386],\n",
              "       [0.9624515 ],\n",
              "       [0.24753524],\n",
              "       [0.20846912],\n",
              "       [0.8759281 ],\n",
              "       [0.1983383 ],\n",
              "       [0.22838828],\n",
              "       [0.39724788],\n",
              "       [0.88303566],\n",
              "       [0.90109515],\n",
              "       [0.6887761 ],\n",
              "       [0.4991853 ],\n",
              "       [0.55095184],\n",
              "       [0.9808291 ],\n",
              "       [0.66293246],\n",
              "       [0.2340609 ],\n",
              "       [0.09371255],\n",
              "       [0.30113596],\n",
              "       [0.16670547],\n",
              "       [0.09758741],\n",
              "       [0.9772729 ],\n",
              "       [0.7462532 ],\n",
              "       [0.93771976],\n",
              "       [0.40836743],\n",
              "       [0.13378839],\n",
              "       [0.09953771],\n",
              "       [0.24958833],\n",
              "       [0.7685083 ],\n",
              "       [0.8115822 ],\n",
              "       [0.18361188],\n",
              "       [0.71526587],\n",
              "       [0.39529234],\n",
              "       [0.4407346 ],\n",
              "       [0.7528695 ],\n",
              "       [0.6710491 ],\n",
              "       [0.2050375 ],\n",
              "       [0.21175751],\n",
              "       [0.9316309 ],\n",
              "       [0.13438644],\n",
              "       [0.69673073],\n",
              "       [0.18548177],\n",
              "       [0.97985363],\n",
              "       [0.21733937],\n",
              "       [0.5186726 ],\n",
              "       [0.5453253 ],\n",
              "       [0.79425246],\n",
              "       [0.37978393],\n",
              "       [0.1903315 ],\n",
              "       [0.9815769 ],\n",
              "       [0.6437388 ],\n",
              "       [0.5078472 ],\n",
              "       [0.10263333],\n",
              "       [0.3612873 ],\n",
              "       [0.64024633],\n",
              "       [0.4427133 ],\n",
              "       [0.0525905 ],\n",
              "       [0.11545093],\n",
              "       [0.6854913 ],\n",
              "       [0.61862844],\n",
              "       [0.8937514 ],\n",
              "       [0.7404952 ],\n",
              "       [0.5160432 ],\n",
              "       [0.94623476],\n",
              "       [0.9230734 ],\n",
              "       [0.1398813 ],\n",
              "       [0.95464855],\n",
              "       [0.20263617],\n",
              "       [0.2419859 ],\n",
              "       [0.40219086],\n",
              "       [0.89173865],\n",
              "       [0.07751811],\n",
              "       [0.78713936],\n",
              "       [0.24434443],\n",
              "       [0.6014772 ],\n",
              "       [0.11786959],\n",
              "       [0.9556854 ],\n",
              "       [0.5136242 ],\n",
              "       [0.06155925],\n",
              "       [0.11040894],\n",
              "       [0.6040312 ],\n",
              "       [0.17827195],\n",
              "       [0.8170908 ],\n",
              "       [0.73034376],\n",
              "       [0.5977317 ],\n",
              "       [0.12137464],\n",
              "       [0.17846046],\n",
              "       [0.97979957],\n",
              "       [0.8759281 ],\n",
              "       [0.4060215 ],\n",
              "       [0.59670126],\n",
              "       [0.9942755 ],\n",
              "       [0.16895175],\n",
              "       [0.46091565],\n",
              "       [0.4750061 ],\n",
              "       [0.11239577],\n",
              "       [0.9834735 ],\n",
              "       [0.8545015 ],\n",
              "       [0.51989996],\n",
              "       [0.8571589 ],\n",
              "       [0.11811692],\n",
              "       [0.46031398],\n",
              "       [0.48088583],\n",
              "       [0.63505846],\n",
              "       [0.26754785],\n",
              "       [0.9407417 ],\n",
              "       [0.9119373 ],\n",
              "       [0.12994726],\n",
              "       [0.61897904],\n",
              "       [0.11998572],\n",
              "       [0.24463263],\n",
              "       [0.32329974],\n",
              "       [0.6007561 ],\n",
              "       [0.44905588],\n",
              "       [0.99263394],\n",
              "       [0.7739698 ],\n",
              "       [0.448047  ],\n",
              "       [0.2452261 ],\n",
              "       [0.4636059 ],\n",
              "       [0.7261533 ],\n",
              "       [0.9856866 ],\n",
              "       [0.76008385],\n",
              "       [0.87497395],\n",
              "       [0.46029255],\n",
              "       [0.18321548],\n",
              "       [0.9845701 ],\n",
              "       [0.95003694],\n",
              "       [0.09987924],\n",
              "       [0.04146418],\n",
              "       [0.14883828],\n",
              "       [0.87965584],\n",
              "       [0.31712285],\n",
              "       [0.976015  ],\n",
              "       [0.15227772],\n",
              "       [0.15676466],\n",
              "       [0.3215318 ],\n",
              "       [0.20665029],\n",
              "       [0.7593095 ],\n",
              "       [0.20846912],\n",
              "       [0.47672448],\n",
              "       [0.5043907 ],\n",
              "       [0.34992334],\n",
              "       [0.10255852],\n",
              "       [0.15252534],\n",
              "       [0.5356572 ],\n",
              "       [0.9913819 ],\n",
              "       [0.9863934 ],\n",
              "       [0.2641008 ],\n",
              "       [0.9032588 ],\n",
              "       [0.9064257 ],\n",
              "       [0.8383516 ],\n",
              "       [0.8700376 ],\n",
              "       [0.73361707],\n",
              "       [0.328179  ],\n",
              "       [0.9491701 ],\n",
              "       [0.12914607],\n",
              "       [0.57577914],\n",
              "       [0.8393381 ],\n",
              "       [0.49894288],\n",
              "       [0.44454107],\n",
              "       [0.25782403],\n",
              "       [0.26259783],\n",
              "       [0.8729512 ],\n",
              "       [0.04795703],\n",
              "       [0.7811982 ],\n",
              "       [0.23672459],\n",
              "       [0.94965386],\n",
              "       [0.24021435],\n",
              "       [0.6475488 ]], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions with the test data\n",
        "predictions = nn_model.predict(X_test_scaled,verbose=2)\n",
        "\n",
        "\n",
        "# Display a sample of the predictions\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "87o8exFPhjfl",
        "outputId": "da5339c5-cea7-43e4-ec22-e168ea16dfa2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     predictions\n",
              "0            0.0\n",
              "1            0.0\n",
              "2            1.0\n",
              "3            1.0\n",
              "4            1.0\n",
              "..           ...\n",
              "395          1.0\n",
              "396          0.0\n",
              "397          1.0\n",
              "398          0.0\n",
              "399          1.0\n",
              "\n",
              "[400 rows x 1 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the predictions to a DataFrame and round the predictions to binary results\n",
        "predictions_df = pd.DataFrame(columns=[\"predictions\"], data=predictions)\n",
        "predictions_df[\"predictions\"] = round(predictions_df[\"predictions\"],0)\n",
        "predictions_df\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxxLwycg6q62"
      },
      "source": [
        "### Step 4: Display a classification report with the y test data and predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTxYZibW6q67",
        "outputId": "f341b396-9b4c-478c-dba8-f6d904ba10e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.77      0.74       188\n",
            "           1       0.78      0.73      0.76       212\n",
            "\n",
            "    accuracy                           0.75       400\n",
            "   macro avg       0.75      0.75      0.75       400\n",
            "weighted avg       0.75      0.75      0.75       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the classification report with the y test data and predictions\n",
        "print(classification_report(y_test, predictions_df[\"predictions\"].values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Aaof1tBtcp6"
      },
      "source": [
        "---\n",
        "## Discuss creating a recommendation system for student loans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CC8cNpNtcp6"
      },
      "source": [
        "Briefly answer the following questions in the space provided:\n",
        "\n",
        "1. Describe the data that you would need to collect to build a recommendation system to recommend student loan options for students. Explain why this data would be relevant and appropriate.\n",
        "\n",
        "2. Based on the data you chose to use in this recommendation system, would your model be using collaborative filtering, content-based filtering, or context-based filtering? Justify why the data you selected would be suitable for your choice of filtering method.\n",
        "\n",
        "3. Describe two real-world challenges that you would take into consideration while building a recommendation system for student loans. Explain why these challenges would be of concern for a student loan recommendation system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KqIT8kYtcp6"
      },
      "source": [
        "**1. Describe the data that you would need to collect to build a recommendation system to recommend student loan options for students. Explain why this data would be relevant and appropriate.**\n",
        "\n",
        "\n",
        "**2. Based on the data you chose to use in this recommendation system, would your model be using collaborative filtering, content-based filtering, or context-based filtering? Justify why the data you selected would be suitable for your choice of filtering method.**\n",
        "\n",
        "\n",
        "**3. Describe two real-world challenges that you would take into consideration while building a recommendation system for student loans. Explain why these challenges would be of concern for a student loan recommendation system.**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
